{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T08:45:57.421529Z",
     "start_time": "2025-06-02T08:40:34.175989Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(data_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # Read labels from CSV\n",
    "    labels_df = pd.read_csv('dataset/labels.csv', skiprows=2)\n",
    "\n",
    "    # Define category directories\n",
    "    categories = ['numerals', 'vowels', 'consonants']\n",
    "\n",
    "    # Process each category\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join(data_dir, 'nhcd', 'nhcd', category)\n",
    "        if os.path.exists(category_dir):\n",
    "            # Process each class directory within the category\n",
    "            for class_dir in os.listdir(category_dir):\n",
    "                class_path = os.path.join(category_dir, class_dir)\n",
    "                if os.path.isdir(class_path):\n",
    "                    try:\n",
    "                        class_idx = int(class_dir)  # Convert directory name to class index\n",
    "                        # Process all images in this class directory\n",
    "                        for img_name in os.listdir(class_path):\n",
    "                            if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                                img_path = os.path.join(class_path, img_name)\n",
    "                                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                                if img is not None:\n",
    "                                    img = cv2.resize(img, (32, 32))\n",
    "                                    data.append(img)\n",
    "                                    labels.append(class_idx)\n",
    "                    except ValueError:\n",
    "                        print(f\"Warning: Could not convert directory name to class index: {class_dir}\")\n",
    "                        continue\n",
    "\n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"No images were loaded. Please check the dataset directory structure and image files.\")\n",
    "\n",
    "    print(f\"Loaded {len(data)} images with {len(np.unique(labels))} unique classes\")\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "def create_model(num_classes):\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 1)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Dense Layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model():\n",
    "    # Load and preprocess data\n",
    "    data_dir = 'dataset'\n",
    "    X, y = load_data(data_dir)\n",
    "  \n",
    "    # Get number of unique classes\n",
    "    num_classes = len(np.unique(y))\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "    # Reshape and normalize data\n",
    "    X = X.reshape(-1, 32, 32, 1) / 255.0\n",
    "    y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and compile model\n",
    "    model = create_model(num_classes=num_classes)\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint = ModelCheckpoint('best_model.h5',\n",
    "                               monitor='val_accuracy',\n",
    "                               save_best_only=True,\n",
    "                               mode='max',\n",
    "                               verbose=1)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                 patience=10,\n",
    "                                 restore_best_weights=True)\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(X_train, y_train,\n",
    "                       batch_size=32,\n",
    "                       epochs=50,\n",
    "                       validation_data=(X_test, y_test),\n",
    "                       callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Evaluate model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = train_model()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12912 images with 37 unique classes\n",
      "Number of classes: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Plan Ghimire\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m320\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │         \u001B[38;5;34m9,248\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m18,496\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m36,928\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m64\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m64\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │        \u001B[38;5;34m73,856\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │       \u001B[38;5;34m147,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │     \u001B[38;5;34m1,049,088\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │         \u001B[38;5;34m2,048\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m37\u001B[0m)             │        \u001B[38;5;34m18,981\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,981</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,358,341\u001B[0m (5.18 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,358,341</span> (5.18 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,356,421\u001B[0m (5.17 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,356,421</span> (5.17 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m1,920\u001B[0m (7.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.2902 - loss: 2.9678\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21448, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 41ms/step - accuracy: 0.2907 - loss: 2.9651 - val_accuracy: 0.2145 - val_loss: 3.4635\n",
      "Epoch 2/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 71ms/step - accuracy: 0.7087 - loss: 0.9635\n",
      "Epoch 2: val_accuracy improved from 0.21448 to 0.79907, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 75ms/step - accuracy: 0.7088 - loss: 0.9631 - val_accuracy: 0.7991 - val_loss: 0.6526\n",
      "Epoch 3/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8199 - loss: 0.5562\n",
      "Epoch 3: val_accuracy improved from 0.79907 to 0.86798, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 37ms/step - accuracy: 0.8199 - loss: 0.5562 - val_accuracy: 0.8680 - val_loss: 0.4119\n",
      "Epoch 4/50\n",
      "\u001B[1m322/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.8636 - loss: 0.4311\n",
      "Epoch 4: val_accuracy improved from 0.86798 to 0.91173, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 37ms/step - accuracy: 0.8636 - loss: 0.4311 - val_accuracy: 0.9117 - val_loss: 0.2866\n",
      "Epoch 5/50\n",
      "\u001B[1m322/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9057 - loss: 0.3061\n",
      "Epoch 5: val_accuracy did not improve from 0.91173\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 37ms/step - accuracy: 0.9056 - loss: 0.3062 - val_accuracy: 0.8997 - val_loss: 0.3394\n",
      "Epoch 6/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9108 - loss: 0.2759\n",
      "Epoch 6: val_accuracy improved from 0.91173 to 0.93302, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 37ms/step - accuracy: 0.9108 - loss: 0.2759 - val_accuracy: 0.9330 - val_loss: 0.2303\n",
      "Epoch 7/50\n",
      "\u001B[1m322/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.9290 - loss: 0.2197\n",
      "Epoch 7: val_accuracy did not improve from 0.93302\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 37ms/step - accuracy: 0.9290 - loss: 0.2197 - val_accuracy: 0.9322 - val_loss: 0.2275\n",
      "Epoch 8/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.9431 - loss: 0.1758\n",
      "Epoch 8: val_accuracy did not improve from 0.93302\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 41ms/step - accuracy: 0.9431 - loss: 0.1758 - val_accuracy: 0.9288 - val_loss: 0.2625\n",
      "Epoch 9/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.9378 - loss: 0.1954\n",
      "Epoch 9: val_accuracy did not improve from 0.93302\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 40ms/step - accuracy: 0.9378 - loss: 0.1953 - val_accuracy: 0.9299 - val_loss: 0.2257\n",
      "Epoch 10/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.9537 - loss: 0.1385\n",
      "Epoch 10: val_accuracy improved from 0.93302 to 0.94154, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 40ms/step - accuracy: 0.9537 - loss: 0.1385 - val_accuracy: 0.9415 - val_loss: 0.2065\n",
      "Epoch 11/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9563 - loss: 0.1317\n",
      "Epoch 11: val_accuracy improved from 0.94154 to 0.94890, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 38ms/step - accuracy: 0.9563 - loss: 0.1317 - val_accuracy: 0.9489 - val_loss: 0.1730\n",
      "Epoch 12/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.9584 - loss: 0.1230\n",
      "Epoch 12: val_accuracy improved from 0.94890 to 0.95470, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 62ms/step - accuracy: 0.9584 - loss: 0.1230 - val_accuracy: 0.9547 - val_loss: 0.1729\n",
      "Epoch 13/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - accuracy: 0.9616 - loss: 0.1228\n",
      "Epoch 13: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 60ms/step - accuracy: 0.9615 - loss: 0.1228 - val_accuracy: 0.9419 - val_loss: 0.1967\n",
      "Epoch 14/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9567 - loss: 0.1299\n",
      "Epoch 14: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 38ms/step - accuracy: 0.9567 - loss: 0.1299 - val_accuracy: 0.9361 - val_loss: 0.2281\n",
      "Epoch 15/50\n",
      "\u001B[1m322/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.9634 - loss: 0.1130\n",
      "Epoch 15: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 40ms/step - accuracy: 0.9634 - loss: 0.1130 - val_accuracy: 0.9400 - val_loss: 0.2274\n",
      "Epoch 16/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.9648 - loss: 0.1032\n",
      "Epoch 16: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 40ms/step - accuracy: 0.9648 - loss: 0.1032 - val_accuracy: 0.9261 - val_loss: 0.3984\n",
      "Epoch 17/50\n",
      "\u001B[1m322/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9706 - loss: 0.0921\n",
      "Epoch 17: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 39ms/step - accuracy: 0.9706 - loss: 0.0922 - val_accuracy: 0.9489 - val_loss: 0.2011\n",
      "Epoch 18/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9716 - loss: 0.0805\n",
      "Epoch 18: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 38ms/step - accuracy: 0.9716 - loss: 0.0806 - val_accuracy: 0.8262 - val_loss: 0.6405\n",
      "Epoch 19/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.9732 - loss: 0.0807\n",
      "Epoch 19: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 38ms/step - accuracy: 0.9732 - loss: 0.0807 - val_accuracy: 0.9489 - val_loss: 0.1968\n",
      "Epoch 20/50\n",
      "\u001B[1m322/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9779 - loss: 0.0692\n",
      "Epoch 20: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 39ms/step - accuracy: 0.9779 - loss: 0.0692 - val_accuracy: 0.9504 - val_loss: 0.1936\n",
      "Epoch 21/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 80ms/step - accuracy: 0.9754 - loss: 0.0739\n",
      "Epoch 21: val_accuracy did not improve from 0.95470\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 82ms/step - accuracy: 0.9754 - loss: 0.0739 - val_accuracy: 0.9501 - val_loss: 0.1825\n",
      "Epoch 22/50\n",
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9747 - loss: 0.0768\n",
      "Epoch 22: val_accuracy improved from 0.95470 to 0.95819, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m323/323\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 37ms/step - accuracy: 0.9747 - loss: 0.0768 - val_accuracy: 0.9582 - val_loss: 0.1767\n",
      "\u001B[1m81/81\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9529 - loss: 0.1747\n",
      "\n",
      "Test accuracy: 0.9547\n",
      "Test loss: 0.1729\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "417a1ec3e65d07ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T08:49:52.557286Z",
     "start_time": "2025-06-02T08:49:52.360029Z"
    }
   },
   "source": [
    "# Save the trained model and metadata\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save the model\n",
    "model_path = 'models/devanagari_model.h5'\n",
    "model.save(model_path)\n",
    "\n",
    "# We know there are 37 classes from the training\n",
    "num_classes = 37  # This is the total number of classes (numerals + vowels + consonants)\n",
    "class_mapping = {i: str(i) for i in range(num_classes)}\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'num_classes': num_classes,\n",
    "    'class_mapping': class_mapping,\n",
    "    'input_shape': (32, 32, 1)\n",
    "}\n",
    "np.save('models/model_metadata.npy', metadata)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Metadata saved to models/model_metadata.npy\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/devanagari_model.h5\n",
      "Metadata saved to models/model_metadata.npy\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:49:42.571944Z",
     "start_time": "2025-06-02T09:49:42.557063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings # Import warnings to suppress the load_model warning\n",
    "\n",
    "def predict_devanagari_character(image_path, model_path='models/devanagari_model.h5', metadata_path='models/model_metadata.npy'):\n",
    "    \"\"\"\n",
    "    Predict Devanagari character from an image\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        model_path: Path to the saved model\n",
    "        metadata_path: Path to the model metadata\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class index\n",
    "        confidence: The confidence score for the prediction\n",
    "    \"\"\"\n",
    "    # Load the model and metadata\n",
    "    # Suppress the warning about compiled metrics not being built\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        model = load_model(model_path)\n",
    "\n",
    "    metadata = np.load(metadata_path, allow_pickle=True).item()\n",
    "\n",
    "    # Read and preprocess the image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image at {image_path}\")\n",
    "\n",
    "    # Resize image to match model's expected input\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "\n",
    "    # Normalize and reshape image\n",
    "    img = img.reshape(1, 32, 32, 1) / 255.0\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = model.predict(img)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class]\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "def get_character_info(class_idx):\n",
    "    \"\"\"\n",
    "    Get information about the predicted character from the labels.csv file\n",
    "\n",
    "    Args:\n",
    "        class_idx: The predicted class index\n",
    "\n",
    "    Returns:\n",
    "        character_info: Dictionary containing character information, or None if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the labels file, skipping the initial rows\n",
    "        labels_df = pd.read_csv('dataset/labels.csv', skiprows=2)\n",
    "\n",
    "        # Ensure 'Class' column is treated as numeric and drop rows with NaN in 'Class'\n",
    "        labels_df['Class'] = pd.to_numeric(labels_df['Class'], errors='coerce')\n",
    "        character_row = labels_df.dropna(subset=['Class'])[labels_df['Class'] == class_idx]\n",
    "\n",
    "        if not character_row.empty:\n",
    "            # Extract information from the first matching row\n",
    "            info = character_row.iloc[0]\n",
    "            character_info = {\n",
    "                'type': info.get('Category', 'Unknown Category'), # Use .get for safety\n",
    "                'label': info.get('Label', 'N/A'),\n",
    "                'devanagari': info.get('Devanagari Label', 'N/A'),\n",
    "                'phonetics': info.get('Phonetics', 'N/A')\n",
    "            }\n",
    "            return character_info\n",
    "        else:\n",
    "            print(f\"Debug: No matching class index {class_idx} found in labels.csv\")\n",
    "            return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: labels.csv not found. Make sure it's in the 'dataset' directory.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading labels.csv: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "def predict_and_display(image_path):\n",
    "    \"\"\"\n",
    "    Predict character and display results with the image\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make prediction\n",
    "        predicted_class, confidence = predict_devanagari_character(image_path)\n",
    "\n",
    "        # Get character information\n",
    "        character_info = get_character_info(predicted_class)\n",
    "\n",
    "        # Display results\n",
    "        print(\"\\nPrediction Results:\")\n",
    "        print(f\"Confidence: {confidence:.2%}\")\n",
    "\n",
    "        devanagari_char = \"Unknown\"\n",
    "        if character_info:\n",
    "            devanagari_char = character_info.get('devanagari', 'Unknown')\n",
    "            print(f\"Type: {character_info.get('type', 'N/A')}\")\n",
    "            print(f\"Label: {character_info.get('label', 'N/A')}\")\n",
    "            print(f\"Devanagari: {devanagari_char}\")\n",
    "            print(f\"Phonetics: {character_info.get('phonetics', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"Could not find character information for predicted class index {predicted_class}\")\n",
    "            # Fallback to predicted class index if character info is not found\n",
    "            devanagari_char = f\"Class: {predicted_class}\"\n",
    "\n",
    "\n",
    "        # Display the image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            # Use the determined Devanagari character (or fallback) for the title\n",
    "            plt.title(f\"Predicted: {devanagari_char}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Could not load image for display: {image_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error during prediction: {ve}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"An unexpected error occurred: {ex}\")\n"
   ],
   "id": "883a2849b0aaceb6",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:50:22.534279Z",
     "start_time": "2025-06-02T09:50:21.889186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: Test with an image from your dataset\n",
    "test_image_path = \"dataset/nhcd/nhcd/numerals/5/001_01.jpg\"  # Replace with an actual image path\n",
    "predict_and_display(test_image_path)"
   ],
   "id": "79be79931c3e228e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 258ms/step\n",
      "\n",
      "Prediction Results:\n",
      "Confidence: 100.00%\n",
      "Type: Unknown Category\n",
      "Label: 5\n",
      "Devanagari: ५\n",
      "Phonetics: pām̐ca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Plan Ghimire\\AppData\\Local\\Temp\\ipykernel_37248\\4053660958.py:64: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  character_row = labels_df.dropna(subset=['Class'])[labels_df['Class'] == class_idx]\n",
      "C:\\Users\\Plan Ghimire\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 2411 (\\N{DEVANAGARI DIGIT FIVE}) missing from font(s) Arial.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\Plan Ghimire\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFcCAYAAACqUye+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAV60lEQVR4nO3dZ2yWBRfG8dNC6YaypGJxgKRICxSkDGVJxQCCURSJDLeCrAipA0cE9SUKFqwFQRxMlUTBFdkCSsBEloMVK0JiEaqMAi2d9Hk/GJq3wuE9R32gwv+X9APt1bt37+fpxd3C6QkJBAIBAQCcJvR8nwAAVFUUJAAoKEgAUFCQAKCgIAFAQUECgIKCBAAFBQkACgoSVRpzDDifKMgL2JAhQyQxMbHSS3JysnTr1k0mTJggR48eDdrHXrx4sSQmJkpOTo6IiGRlZUliYqL5/Q8cOCBDhw6Vffv2/e1zycnJkcTERFm8ePHfPhYuLtXP9wkguJo3by7PPfdcxZ9LS0tl+/btMmXKFNm5c6e8//77EhISEvTz6N+/v3Tu3Nmc37Bhg6xdu1aeffbZIJ7V2ZWXl8ukSZPOen169eolLVu2PIdnhXOJgrzAxcTESEpKSqXXpaamSkFBgbz22mvy3Xffnfb2YIiPj5f4+Pigf5x/Unl5udxwww3Svn17NbNhw4ZzeEY41/gW+yKVnJwsIiK//vqriPzx7Xh6erqMHj1a2rRpIw8//LCIiBQXF8ukSZOka9eukpycLH379pUlS5ZUOlZ5ebm8/vrr0q1bN2nVqpUMHz78tG/fz/Qt9ueffy79+vWTVq1aSbdu3WTy5MlSUlIiixcvlnHjxomISFpamjz55JMV7/PBBx/IzTffXPGjgqysLCkrK6t03BUrVsgtt9wiLVu2lNtuu0127dp12uffvXt3GTJkyF+5dLiIcAd5kdqzZ4+IiDRq1KjidUuXLpWePXvK9OnT5eTJkxIIBGTEiBGyZcsWGT16tDRp0kRWrlwpY8aMkZKSErn11ltFRGTy5Mkyb948GTZsmKSkpMiyZcskIyPjrB9/4cKF8txzz8kdd9whY8aMkZycHJk0aZIcOXJE0tPT5ZFHHpEZM2bItGnTKor1jTfekKlTp8rgwYNl3LhxsnPnTsnKypL9+/fLxIkTRURk9erVMnr0aLn55pslPT1ddu3aJY899thpH3/atGlSo0aNf+JS4gJGQV7gAoFApTuso0ePyjfffCMzZsyQlJSUijtJEZHQ0FB54YUXJCoqSkRE1q9fL+vWrZOpU6dK7969RUSkc+fOUlhYKK+88or06dNHTpw4IfPnz5e7775bRo0aVZHJzc2VdevWnfGcysvLJSsrS3r06CH/+c9/Kl5fXFwsH330kcTExMjll18uIiLXXHONJCQkyPHjx2XGjBkyYMAAeeaZZ0REpFOnThIXFyfPPPOM3HfffdK0aVOZPn26JCUlVRR0ly5dREROK+zmzZv/9YuKiwbfYl/gNm7cKElJSRUv1113nYwdO1aSkpJkypQplf4BIiEhoaIcRUS+/vprCQkJka5du0pZWVnFS/fu3eX333+X7Oxs+fbbb6W0tFTS0tIqfdxevXqp57Rnzx45ePCg3HjjjZVef++998onn3xyxju7rVu3SmFhoXTv3v20cxH5o8yLiopk+/btrnMBzoY7yAtcUlKSTJgwQUREQkJCJDw8XC699FKJiYk5LVuvXr1Kf87Ly5NAICBt2rQ547F/++03OXbsmIiI1KlTp9Lb6tevr55TXl6eiIjUrVvX/Hmcep9TPxs907kcPXpUAoHAaedyySWXmD8O8L8oyAtcdHS0tGjR4i+9b2xsrERFRcm8efPO+PYrrrhCvv/+exEROXTokDRu3LjibacK7Uxq1qwpIiKHDx+u9Pq8vDzZvn37Gf9V/dT7vPLKK3LllVee9vZ69epJXFychIaGysGDB087LvBX8C02VO3atZMTJ05IIBCQFi1aVLxkZ2fL9OnTpaysTFq3bi0RERGybNmySu+7Zs0a9biNGzeW2rVryxdffFHp9Z999pk89NBDUlxcLKGhlZ+arVq1krCwMMnNza10LmFhYZKRkSE5OTkSHh4urVu3lhUrVlSawFm9evU/cDVwMeIOEqquXbtKamqqDB8+XIYPHy5NmjSR77//XrKysqRTp04V38oOHz5cXn31VYmMjJQOHTrIl19+edaCrFatmowaNUqef/55GT9+vPTo0UP27t0rr776qtx1111Sp06dijvGlStXSpcuXaRJkyby4IMPSmZmpuTn50v79u0lNzdXMjMzJSQkRJo1ayYiImPHjpV77rlHRo4cKQMGDJC9e/fKjBkzTjuHHTt2SI0aNeTqq68OwpXDhYKChCo0NFRmzZolmZmZ8sYbb8ihQ4ekQYMGcu+998qIESMqckOHDpWoqCiZO3euzJ07V1q3bi1PPPGEjB8/Xj32oEGDJCoqSt5++2358MMPpUGDBnL//fdX/Iyxffv2ct1110lGRoZ8/fXXMmvWLHn00Uelfv368t5778lbb70ltWrVko4dO8rYsWMlNjZWRETatm0rb775pkyZMkVGjhwpCQkJMnHiRBk2bFiljz9y5Ei57LLLZP78+We9Bu+//76sXbtWffu5+E/2OH9C2GoIAGfGzyABQEFBAoCCggQABQUJAAoKEgAUFCQAKChIAFCY/6O4579Lnotf4f9P8nxuwcr++Ze+nk1YWJg5++eRvbOZM2eOOfvUU0+Zsx06dDBn/9/vkfxfV1xxhTnreSyKi4vN2fDwcHO2WrVq5mxJSYk5e/LkSXPW8zswPc8dz9e857nuuWb5+fnm7KnBgv+HO0gAUFCQAKCgIAFAQUECgIKCBAAFBQkACgoSABQUJAAoKEgAUFCQAKBgJ00V4RkBKyoqMmc9Y4mekbWCggJzNjs725zds2ePOXvVVVeZs6WlpeZs9er2LwvPiJ3nHMrLy83ZyMhIc9bDM7rnuWYRERHm7Km96xanFr39k7iDBAAFBQkACgoSABQUJAAoKEgAUFCQAKCgIAFAQUECgIKCBAAFBQkACkYNqwjPyJpn05tnvM0zaugZd/SMGv7www/m7LXXXmvOekY5PY+FJ+sZ+/y3bQb1nK9na+TmzZvN2cTERHO2YcOGphx3kACgoCABQEFBAoCCggQABQUJAAoKEgAUFCQAKChIAFBQkACgoCABQMGoYRURCATMWc/YnOe4sbGx5mzt2rXN2dzcXHP2999/N2c9n5tn819JSYk569k+6BkR9ZyDZ+zT89zxbB/0XIfZs2ebswsXLjRne/bsac4+8cQTphx3kACgoCABQEFBAoCCggQABQUJAAoKEgAUFCQAKChIAFBQkACgoCABQMGoYRXh2fQWHh5uznq2zV199dXmbHJysjnrGTU8fPiwORsXF2fOesYSPTybIMvKyszZ6tXtX5qe8UEPz2OxZcsWc3bmzJnmbH5+vjnr2WpoxR0kACgoSABQUJAAoKAgAUBBQQKAgoIEAAUFCQAKChIAFBQkACgoSABQMGpYRXjGxTwb7zxjiU2bNjVn27VrZ86uXr3anP3uu+/M2d27d5uzl19+uTkbrNG9YG0q9Izjffvtt+bs8uXLzdk5c+aYs54xyhEjRpizN910kzlrxR0kACgoSABQUJAAoKAgAUBBQQKAgoIEAAUFCQAKChIAFBQkACgoSABQMGpYRYSGBufvqtLSUnPWsyUwLS3NnF25cqU5m52dbc5mZmaas3379jVnw8LCzFnP43bo0CFzds+ePUHJerYPbtq0yZyNj483Z59++mlzduDAgeZsVFSUOWvFHSQAKChIAFBQkACgoCABQEFBAoCCggQABQUJAAoKEgAUFCQAKChIAFCEBAKBgCVojP1x0JCQv3xC54PncwtW1uPkyZPmbHFxsTkbGxsblONOnjzZnJ0+fbo569n85xmjPHbsmDkbERFhzkZGRpqz+/fvN2dPnDgRlHNo3LixOfv444+bs4MHDzZnPY+FZ2vkJZdcYspxBwkACgoSABQUJAAoKEgAUFCQAKCgIAFAQUECgIKCBAAFBQkACgoSABSMGkrwRgI916G8vNyc9WzS84wlBsvevXvN2fXr15uz27dvN2e/+uorc/aqq64yZxs2bGjO5ufnm7Pr1q0zZ3fs2GHOdujQwZx98cUXzdnOnTubs8Hi+Xqzbq7kDhIAFBQkACgoSABQUJAAoKAgAUBBQQKAgoIEAAUFCQAKChIAFBQkACjMo4bBUhXG/KoCz0Y2z6ihR/Xq1YNy3GA5cuRIULI1atQwZ7Ozs83ZjIwMc3bp0qXm7O23327Opqenm7MJCQnmbL169cxZj2B9HTNqCAB/EwUJAAoKEgAUFCQAKChIAFBQkACgoCABQEFBAoCCggQABQUJAIrzPmro4dnQ59kSWBUugWe8rayszJz1fG7W8SsRkcLCQnPWs80vIiLCnI2NjTVnPTZt2mTOesYH165da8526dLFnPWMD6amppqzHqWlpUE5brBGDa1jtdxBAoCCggQABQUJAAoKEgAUFCQAKChIAFBQkACgoCABQEFBAoCCggQAhXnU0DPm5xkPClb238YzGunZgOgZ3fPwnK+H5zH2jDt+8skn5uy7775rzm7YsMGc7devnzn7/PPPm7MNGzY0Z3Nzc83Z6OhoczZYz7Ngfc1Xq1bNlOMOEgAUFCQAKChIAFBQkACgoCABQEFBAoCCggQABQUJAAoKEgAUFCQAKMyjhp7teJ4xNE/WM3YUGhqc7vdcB894ZlFRkTlbs2ZNc9bDcw6eLYwentG9jz/+2JxdtGiRORseHm7ODhgwwJwdOnSoOesZH/RsubSO2AXzuFWBtR+4gwQABQUJAAoKEgAUFCQAKChIAFBQkACgoCABQEFBAoCCggQABQUJAArzqKGHZ8QuWNvxPKNPnhFGz/l6roPnfI8ePWrOlpaWmrMNGjQwZz1WrVplzk6ZMiUox01NTTVn+/fvb87eeeed5mx8fLw5W1BQYM56xj49Y5QeQagRt2BsQOQOEgAUFCQAKChIAFBQkACgoCABQEFBAoCCggQABQUJAAoKEgAUFCQAKMyjhoWFhfaDBmn7oCfrGfPLz883Zw8fPmzOHj9+3JxdsGCBOXvgwAFz1qNdu3bmbN26dc3ZTz/91Jzdtm2bOdu6dWtz9sknnzRnW7Zsac56eJ5nMTExQTmHY8eOmbORkZHmbFhY2F85nSqPO0gAUFCQAKCgIAFAQUECgIKCBAAFBQkACgoSABQUJAAoKEgAUFCQAKA471sNS0pKzNlDhw6Zsz///LM5u3nzZnP2m2++MWd/+uknc3b37t3mrGcM7ciRI+asZ2Nj7dq1zVmP3r17m7OTJk0yZ+Pi4sxZz4hoRESEOesZxysrKzNng7XB07MRk1FDALjIUJAAoKAgAUBBQQKAgoIEAAUFCQAKChIAFBQkACgoSABQUJAAoKhuDXo2snm2oRUUFJizS5cuNWe/+uorc3br1q3mbNu2bc3ZcePGmbPR0dHm7KpVq8zZOXPmmLOex2Lfvn3mrGcsMSUlxZz1jNh5xMbGmrOe8VfPuGP16uYvTQnCtLCb5xw8447nG3eQAKCgIAFAQUECgIKCBAAFBQkACgoSABQUJAAoKEgAUFCQAKCgIAFAYZ5n8mzS81izZo05+84775iz9erVM2dfeuklc/b66683Zz1jaJmZmebs2rVrzVnPpsK0tDRzNjw83Jxdvny5OTt16lRz1rP578477zRn4+Pjzdm6deuasx6FhYVBOa5nDNizndQzGvlvwh0kACgoSABQUJAAoKAgAUBBQQKAgoIEAAUFCQAKChIAFBQkACgoSABQhASM68h++ukn80Hfeustc3bRokXmbNOmTc3ZBx54wJzt3r27Obt+/XpzdsGCBebsihUrzNmkpCRztk+fPuZsr169zFnPOJ7nOmRlZZmznq2G48ePN2d79+5tztapU8ec9Yx9ejb/VYWRQLYaAsBFhoIEAAUFCQAKChIAFBQkACgoSABQUJAAoKAgAUBBQQKAgoIEAIV51NAzhrZz505zNiUlxZx94YUXzFnPxrv33nvPnJ0zZ445e/DgQXN28ODB5qxnjLJTp07mrIdnZC03N9eczcjIMGc9Y4nNmzc3Z2fOnGnOpqammrOe54NnK6dHXl6eORsXF2fOMmoIABcZChIAFBQkACgoSABQUJAAoKAgAUBBQQKAgoIEAAUFCQAKChIAFOZ5sWXLlpkP2rZtW3O2WbNm5uzq1avN2Y8//tic/eWXX8zZFi1amLPt27c3Z4cMGWLOesbmPDzb8Y4fP27ORkdHm7Oe63DgwAFzdv78+ebsZ599Zs4mJCSYs7GxseZsUVGRORseHm7OekZE8/PzzVnPY/xvwh0kACgoSABQUJAAoKAgAUBBQQKAgoIEAAUFCQAKChIAFBQkACgoSABQmLcaekaU6tata87GxMSYs1FRUeasZytc7969zdm0tDRztnHjxuZsZGSkOevZCldYWGjO1qpVy5z1KC8vN2dDQ+1/Z69atcqcnTBhgjn7448/mrOeDZPp6enmbM2aNc1Zz0bBsLAwc7a4uNicrVGjhjnLVkMAuABQkACgoCABQEFBAoCCggQABQUJAAoKEgAUFCQAKChIAFBQkACgMI8aXnvtteaDera3ebYaduzY0Zy94YYbzNk6deqYsxEREeasZzzTwzNaVlBQYM56Rjk9x/Wcr2fEbv/+/eZsdna2OXvPPfeYs57PbezYseZsjx49zNlGjRqZs57H2DP26bkOjBoCwAWAggQABQUJAAoKEgAUFCQAKChIAFBQkACgoCABQEFBAoCCggQAhXnUcNmyZeaDJicnm7MJCQnmbF5enjkbFxdnzpaVlZmznvHBkydPBuUcSkpKzNno6Ghz1jNa5uE536KiInPWM5boMXXqVHN21qxZ5uzx48fN2WHDhpmzQ4cONWc9zwfPpsJq1aqZs4waAsAFgIIEAAUFCQAKChIAFBQkACgoSABQUJAAoKAgAUBBQQKAgoIEAIV51BC4WHjGPjdu3GjOvvzyy+bshg0bzNkHH3zQnB0zZow56xk1rFWrljmbn59vzp7vLaLcQQKAgoIEAAUFCQAKChIAFBQkACgoSABQUJAAoKAgAUBBQQKAgoIEAMU/P5sDVEGejYKe8baOHTuasyNGjDBnc3Nzzdlp06aZswcOHDBnBw4caM56xhL37dtnzjZs2NCcbdmypTlbu3ZtU447SABQUJAAoKAgAUBBQQKAgoIEAAUFCQAKChIAFBQkACgoSABQUJAAoGCrIfAn5eXl5mxoqP0ew7PNb8mSJebs7NmzzdmtW7easx6tWrUyZ6Ojo83Zfv36mbODBg0yZ0NCQkw57iABQEFBAoCCggQABQUJAAoKEgAUFCQAKChIAFBQkACgoCABQEFBAoCCUUPgbygpKTFnw8LCzFnrKJyISE5Ojjm7atUqc3bbtm3m7IABA8zZmJgYc7ZRo0ZBOa4Vd5AAoKAgAUBBQQKAgoIEAAUFCQAKChIAFBQkACgoSABQUJAAoKAgAUDBqCEAKLiDBAAFBQkACgoSABQUJAAoKEgAUFCQAKCgIAFAQUECgIKCBADFfwGGp830m3ot9gAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6de2e801ccabe1e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
